{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "name": "",
  "signature": "sha256:469b44bc1fd6a2c989234c1fcf4eac5ddf0191c202bfac3897b6ea90bb829ab1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import csv\n",
      "from sklearn.neural_network import MLPClassifier\n",
      "import numpy as np\n",
      "import pickle\n",
      "\n",
      "\n",
      "n_train_samples = 0\n",
      "n_features = 0\n",
      "trainSet_features = []\n",
      "trainSet_labels = []\n",
      "n_test_samples = 0\n",
      "testSet_features = []\n",
      "testSet_labels = []\n",
      "\n",
      "\n",
      "def read_csv_file():\n",
      "    with open('train.csv','rb') as csvFile:\n",
      "        rd = csv.reader(csvFile)\n",
      "        for row in rd:\n",
      "            row_float = [float(i) for i in row]\n",
      "            trainSet_labels.append(row_float.pop(0))\n",
      "            trainSet_features.append(row_float)\n",
      "\n",
      "        global n_train_samples\n",
      "        n_train_samples = len(trainSet_labels)\n",
      "        print(\"Number of train samples is %d\" % n_train_samples)\n",
      "        global n_features\n",
      "        n_features = len(trainSet_features[0])\n",
      "        print(\"Number of features is %d\" % n_features)\n",
      "    print(\"Train set loaded sucessfuly\")\n",
      "\n",
      "    with open('test.csv','rb') as csvFile:\n",
      "        rd = csv.reader(csvFile)\n",
      "        for row in rd:\n",
      "            row_float = [float(i) for i in row]\n",
      "            testSet_labels.append(row_float.pop(0))\n",
      "            testSet_features.append(row_float)\n",
      "\n",
      "        global n_test_samples\n",
      "        n_test_samples = len(testSet_labels)\n",
      "        print(\"Number of test samples is %d\" % n_test_samples)\n",
      "    print(\"Test set loaded sucessfuly\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "\n",
      "print(\"Start MLP\")\n",
      "# read the CSV files\n",
      "read_csv_file()\n",
      "\n",
      "trainSet_features = np.asarray(trainSet_features)\n",
      "trainSet_labels = np.asarray(trainSet_labels)\n",
      "testSet_features = np.asarray(testSet_features)\n",
      "testSet_labels = np.asarray(testSet_labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start MLP\n",
        "Number of train samples is 26999"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of features is 784\n",
        "Train set loaded sucessfuly\n",
        "Number of test samples is 15001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test set loaded sucessfuly\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# optimize hidden layers\n",
      "print(\"Optimizing number of hidden layers\")\n",
      "scores = {}\n",
      "n_Iter = 2\n",
      "for n_h_l in np.arange(160, 210, 50):\n",
      "    avg_acc = 0;\n",
      "    for i in range(n_Iter):\n",
      "        mlp = MLPClassifier(solver = 'sgd', alpha=1e-5, hidden_layer_sizes=(n_h_l,), random_state=1, shuffle=True)\n",
      "        mlp.fit(trainSet_features, trainSet_labels)\n",
      "        avg_acc += mlp.score(testSet_features, testSet_labels)\n",
      "    scores[n_h_l] = avg_acc/n_Iter\n",
      "\n",
      "opt_n_h_l = scores.get(max(scores))\n",
      "print(\"optimal number of hidden layers is %d\" % opt_n_h_l)\n",
      "data = {'opt_n_h_l': opt_n_h_l, 'scores': scores}\n",
      "f = file('variables.pkl', 'wb')\n",
      "pickle.dump(data, f, 2)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}